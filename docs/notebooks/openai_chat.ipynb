{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2bd2cda-4483-4e25-82d9-ca765a8bffb9",
      "metadata": {},
      "source": [
        "# OpenAI Python SDK: Complete Guide\n",
        "\n",
        "üë®‚Äçüíª _**Author:**_ [Mohankumar Ramachandran](https://github.com/mohankumarelec)\n",
        "\n",
        "<span id=\"meta-description\" style=\"display: none;\">Learn how to use the OpenAI Python SDK for chat, text, vision, file input, function calling, and structured output with easy code examples.</span>\n",
        "<span id=\"meta-tags\" style=\"display: none;\">openai</span>\n",
        "<span id=\"meta-created-at\" style=\"display: none;\">2025-07-05T00:00:00Z</span>\n",
        "\n",
        "Welcome to your all-in-one, hands-on OpenAI Python SDK tutorial!  \n",
        "Whether you‚Äôre just starting out or want to master the latest features, this notebook has you covered.\n",
        "\n",
        "You‚Äôll learn, with easy-to-run code:\n",
        "\n",
        "- üîë **Setup & Install** ‚Äì Get your API key, install the SDK\n",
        "- üìù **Text Generation** ‚Äì Write stories & answers\n",
        "- üó£Ô∏è **Chat Roles & Memory** ‚Äì Custom assistants, multi-turn chat\n",
        "- üñºÔ∏è **Vision** ‚Äì Analyze images (URLs & files)\n",
        "- ‚ö° **Streaming** ‚Äì Real-time responses\n",
        "- üõ†Ô∏è **Function Calling** ‚Äì Let AI use your Python tools\n",
        "- üì¶ **Structured Output** ‚Äì Get responses as Python objects\n",
        "- üî¢ **Embeddings** ‚Äì Turn text into vectors\n",
        "\n",
        "Ready to build smarter, richer AI apps? Let‚Äôs dive in! üéâ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5061e9cb-f201-43fc-9e90-4493f6343fc8",
      "metadata": {},
      "source": [
        "## Setup Model API key\n",
        "\n",
        "Run the next cell to setup a free OpenAI API key using your GitHub account, or use your own OpenAI API key.\n",
        "\n",
        "> Note: May not work for enterprise GitHub accounts due to company-specific policies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c65b2d-2d02-4705-bb09-ab9679d2f6f5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# NOTE: Set support_with_star to False if you do not want to support our work yet.\n",
        "from foreverpython import init_github_models\n",
        "\n",
        "# Run below if you already have your own OpenAI API key\n",
        "# import os\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "\n",
        "# else, run below to setup a free GitHub Models API key using your GitHub account.\n",
        "await init_github_models(use_browser_cache=True, support_with_star=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1564ed6f-0b83-4b06-8032-c7471f17da55",
      "metadata": {},
      "source": [
        "## Install OpenAI SDK\n",
        "\n",
        "First, let's install the official OpenAI Python package so you can access all the latest features and models! üì¶‚ú®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a35a9c2-be62-4b0b-9c5e-600275ee8ad3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Install the OpenAI Python SDK\n",
        "%pip install openai==1.93.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36bc8e6b-c4ad-4107-a985-88baeec3f33b",
      "metadata": {},
      "source": [
        "## Text Generation\n",
        "\n",
        "Generating text with OpenAI is super easy! üìù‚ú® You can use the API to write stories, answer questions, or just have fun. Below is a simple example that sends a prompt and gets a creative response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dabb7b2-55aa-45b8-a601-62c3231a98fa",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate a one-sentence bedtime story using OpenAI\n",
        "from openai import OpenAI\n",
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "\n",
        "# Create an OpenAI client to interact with the API\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Create a chat completion (text generation) request\n",
        "bedtime_story_response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",  # Pick a small, fast model\n",
        "    messages=[\n",
        "        ChatCompletionUserMessageParam(\n",
        "            role=\"user\", content=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Print the generated story ü¶Ñ‚ú®\n",
        "print(bedtime_story_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad501f2-b2f2-4e7e-aa6d-26327f4cb84e",
      "metadata": {},
      "source": [
        "## Chat Roles\n",
        "\n",
        "With OpenAI chat models, you can set different roles to control your assistant's behavior! üó£Ô∏è For example, you can make it act like a pirate, a helpful friend, or a professional developer. Roles like `system`, `user`, or even `developer` help guide the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc937e28-af5f-4fbc-8178-2bac33159ab4",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Example: Setting custom roles in conversation\n",
        "from openai import OpenAI\n",
        "from openai.types.chat import ChatCompletionDeveloperMessageParam\n",
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "\n",
        "# Create OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Define a conversation where the assistant talks like a pirate!\n",
        "pirate_chat_response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        # Set behavior of the assistant to talk like a pirate\n",
        "        ChatCompletionDeveloperMessageParam(\n",
        "            role=\"developer\", content=\"Talk like a pirate.\"\n",
        "        ),\n",
        "        # Add question from the user to the conversation\n",
        "        ChatCompletionUserMessageParam(\n",
        "            role=\"user\", content=\"Are semicolons optional in JavaScript?\"\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Print the pirate-themed answer ‚ò†Ô∏è\n",
        "print(pirate_chat_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e46a02e-c799-4107-b866-42867f7547d6",
      "metadata": {},
      "source": [
        "## Conversation Context\n",
        "\n",
        "Want your chatbot to remember what was said earlier? Since OpenAI chat models can handle multiple messages, you can pass a list of messages to keep the conversation flowing naturally! üó®Ô∏èüîÅ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4ce1fe-c964-45a9-8687-834d03790fb5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Keep track of chat history for multi-turn conversations\n",
        "from openai import OpenAI\n",
        "from typing import List, cast\n",
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "from openai.types.chat import ChatCompletionMessageParam\n",
        "from openai.types.chat import ChatCompletionAssistantMessageParam\n",
        "\n",
        "# Create OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Start conversation history with the user's first message\n",
        "conversation_history: List[ChatCompletionMessageParam] = [\n",
        "    ChatCompletionUserMessageParam(role=\"user\", content=\"tell me a joke\")\n",
        "]\n",
        "\n",
        "# First response from the assistant\n",
        "first_joke_response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=conversation_history,\n",
        ")\n",
        "\n",
        "# Extract the assistant's message from the response\n",
        "first_joke_response_message = first_joke_response.choices[0].message\n",
        "\n",
        "print(\"=\" * 50 + \"\\n## First Response:\\n\")\n",
        "print(first_joke_response_message.content)\n",
        "print(\"=\" * 50, \"\\n\")\n",
        "\n",
        "# Add the assistant's reply and a new user prompt to the history\n",
        "conversation_history.append(\n",
        "    cast(ChatCompletionAssistantMessageParam, first_joke_response_message.model_dump())\n",
        ")\n",
        "conversation_history.append(\n",
        "    ChatCompletionUserMessageParam(role=\"user\", content=\"tell me another\")\n",
        ")\n",
        "\n",
        "# Second response (model remembers the context!)\n",
        "second_joke_response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=conversation_history,\n",
        ")\n",
        "\n",
        "print(\"=\" * 50 + \"\\n## Second Response:\\n\")\n",
        "print(second_joke_response.choices[0].message.content)\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2f06198-1117-4ba9-a238-73423b640c6c",
      "metadata": {},
      "source": [
        "## Image Analysis\n",
        "\n",
        "You can ask OpenAI models about images by sending them a URL! üñºÔ∏èü§ñ This is perfect for describing photos, recognizing objects, or even reading text from images (OCR)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0af585-f47e-4376-8597-49512c8a19fc",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Analyze an image from a URL with OpenAI Vision\n",
        "from openai import OpenAI\n",
        "from openai.types.chat import ChatCompletionContentPartImageParam\n",
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "from openai.types.chat import ChatCompletionContentPartTextParam\n",
        "\n",
        "# Create OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Send an image URL and ask \"What's in this image?\"\n",
        "vision_response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        ChatCompletionUserMessageParam(\n",
        "            role=\"user\",\n",
        "            content=[\n",
        "                ChatCompletionContentPartTextParam(\n",
        "                    type=\"text\", text=\"What's in this image?\"\n",
        "                ),\n",
        "                ChatCompletionContentPartImageParam(\n",
        "                    type=\"image_url\",\n",
        "                    image_url={\n",
        "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
        "                    },\n",
        "                ),\n",
        "            ],\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Print the AI's description üå≥ü¶Ü\n",
        "print(vision_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a70d929-d08e-4a8e-a221-04b7caf4c6bd",
      "metadata": {},
      "source": [
        "## File Image Input\n",
        "\n",
        "You can also upload images (or even PDFs!) directly from your computer. üìÅ Just encode your image as Base64 and send it to the API. This is handy if your image isn't available online."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a9b6d3-480a-4511-846c-e8f6737aeaa8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Analyze a local image by encoding it as Base64\n",
        "import base64\n",
        "from openai import OpenAI\n",
        "from openai.types.chat import ChatCompletionContentPartImageParam\n",
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "from openai.types.chat import ChatCompletionContentPartTextParam\n",
        "\n",
        "# Create OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Specify your local image file path here\n",
        "local_image_path = \"./sample_data/green_pathway.jpg\"\n",
        "\n",
        "\n",
        "# Function to read an image file and return its Base64 encoded string\n",
        "def get_base64_encoded_image(path_to_image):\n",
        "    \"\"\"Read the file and return its Base64 string.\"\"\"\n",
        "    with open(path_to_image, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "# Encode the image\n",
        "base64_image_str = get_base64_encoded_image(local_image_path)\n",
        "\n",
        "# Send the image to the model for analysis\n",
        "image_analysis_response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        ChatCompletionUserMessageParam(\n",
        "            role=\"user\",\n",
        "            content=[\n",
        "                ChatCompletionContentPartTextParam(\n",
        "                    type=\"text\", text=\"What's in this image?\"\n",
        "                ),\n",
        "                ChatCompletionContentPartImageParam(\n",
        "                    type=\"image_url\",\n",
        "                    image_url={\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image_str}\",\n",
        "                    },\n",
        "                ),\n",
        "            ],\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Print the AI's answer! üñºÔ∏èüîç\n",
        "print(image_analysis_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9988902-e142-4d6f-89a2-6c383c3a28b2",
      "metadata": {},
      "source": [
        "## Streaming Output\n",
        "\n",
        "Want your app to feel lightning fast? ‚ö° Try streaming responses! With streaming, you can see the output as it's being generated‚Äîperfect for chatbots and dynamic UIs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42edf4b2-2eec-4446-b401-f1410322d385",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Stream a long OpenAI chunk by chunk\n",
        "from openai import OpenAI\n",
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "\n",
        "# Create OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Start a streaming chat completion for a longer prompt\n",
        "streamed_story = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        ChatCompletionUserMessageParam(\n",
        "            role=\"user\",\n",
        "            content=\"Write me a big story about `Attention Is All You Need` research paper\",\n",
        "        ),\n",
        "    ],\n",
        "    stream=True,  # Enable streaming!\n",
        ")\n",
        "\n",
        "# Print each chunk as it arrives, for a real-time feel üí®\n",
        "for response_chunk in streamed_story:\n",
        "    if len(response_chunk.choices) and response_chunk.choices[0].delta.content:\n",
        "        print(response_chunk.choices[0].delta.content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ae4fd82-698b-42cc-a333-431ce55c1276",
      "metadata": {},
      "source": [
        "## Tool / Function Calling\n",
        "\n",
        "Tool calling lets your AI assistant use your own Python functions as tools! üõ†Ô∏è This means you can dramatically increase what your model can do.\n",
        "\n",
        "- Fetch real data, like the current weather or stock prices  \n",
        "- Perform live calculations  \n",
        "- Connect to APIs or extend your assistant with any Python logic you need"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6188a8d0",
      "metadata": {},
      "source": [
        "### ü•á Method 1: Define a Tool using JSON Schema\n",
        "\n",
        "You can define a tool for the model directly using a JSON schema. This is great when you want to specify the parameters and their types in a standard way.\n",
        "\n",
        "**When to use:** If you want a quick and flexible way to define tool inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eacf059e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries for tool calling\n",
        "from openai import OpenAI\n",
        "from openai.types.chat import ChatCompletionUserMessageParam, ChatCompletionToolParam\n",
        "\n",
        "# Create an OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Define a tool using JSON schema for a weather function\n",
        "weather_tool_schema = ChatCompletionToolParam(\n",
        "    type=\"function\",\n",
        "    function={\n",
        "        \"name\": \"get_weather\",\n",
        "        \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"latitude\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"Latitude of the location to get weather for.\",\n",
        "                },\n",
        "                \"longitude\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"Longitude of the location to get weather for.\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"latitude\", \"longitude\"],\n",
        "            \"additionalProperties\": False,\n",
        "        },\n",
        "        \"strict\": True,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Use the tool with the model\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        ChatCompletionUserMessageParam(\n",
        "            role=\"user\",\n",
        "            content=\"What's the weather like in Bangalore today and its air quality?\",\n",
        "        )\n",
        "    ],\n",
        "    tools=[weather_tool_schema],\n",
        ")\n",
        "\n",
        "# Print the model's tool call response\n",
        "response.choices[0].message.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f4a907",
      "metadata": {},
      "source": [
        "### ü•à Method 2: Define a Tool using Pydantic Models\n",
        "\n",
        "You can also define tools using Pydantic models, which gives you automatic input validation and clear documentation for your tool's inputs.\n",
        "\n",
        "**When to use:** If your tool requires strong type safety or you want to leverage Pydantic's validation features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8286da27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries for tool calling with Pydantic\n",
        "from openai import OpenAI, pydantic_function_tool\n",
        "from pydantic import BaseModel, Field\n",
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "\n",
        "# Create an OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "\n",
        "# Define a Pydantic schema for the weather tool\n",
        "class WeatherToolSchema(BaseModel):\n",
        "    \"\"\"Get current temperature for provided coordinates in celsius.\"\"\"\n",
        "\n",
        "    latitude: float = Field(\n",
        "        ..., description=\"Latitude of the location to get weather for.\"\n",
        "    )\n",
        "    longitude: float = Field(\n",
        "        ..., description=\"Longitude of the location to get weather for.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Register this Pydantic model as a tool\n",
        "weather_tool_schema = pydantic_function_tool(WeatherToolSchema, name=\"get_weather\")\n",
        "\n",
        "# Use the tool with the model\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        ChatCompletionUserMessageParam(\n",
        "            role=\"user\",\n",
        "            content=\"What's the weather like in Bangalore today and its air quality?\",\n",
        "        )\n",
        "    ],\n",
        "    tools=[weather_tool_schema],\n",
        ")\n",
        "\n",
        "# Print the model's tool call response\n",
        "response.choices[0].message.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11cc9449",
      "metadata": {},
      "source": [
        "## Tool Invocation\n",
        "\n",
        "Let's put it all together! We'll define a tool, let the model decide when to call it, and show how you can execute the tool call and return the result to the model.\n",
        "\n",
        "This is how you enable your AI assistant to fetch real data in a live, multi-step conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6474ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import httpx\n",
        "import json\n",
        "from openai import OpenAI, pydantic_function_tool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, cast\n",
        "from openai.types.chat import (\n",
        "    ChatCompletionUserMessageParam,\n",
        "    ChatCompletionAssistantMessageParam,\n",
        "    ChatCompletionMessageParam,\n",
        "    ChatCompletionToolMessageParam,\n",
        ")\n",
        "\n",
        "# Create the OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Maintain the conversation history\n",
        "message_history: List[ChatCompletionMessageParam] = [\n",
        "    ChatCompletionUserMessageParam(\n",
        "        role=\"user\",\n",
        "        content=\"What's the weather like in Bangalore today and its air quality?\",\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "# Define a function to call the Open-Meteo weather API\n",
        "def get_weather(latitude, longitude):\n",
        "    \"\"\"\n",
        "    Calls Open-Meteo weather API to fetch the current temperature for given coordinates.\n",
        "    \"\"\"\n",
        "    with httpx.Client() as client:\n",
        "        response = client.get(\n",
        "            \"https://api.open-meteo.com/v1/forecast\",\n",
        "            params={\n",
        "                \"longitude\": longitude,\n",
        "                \"latitude\": latitude,\n",
        "                \"current\": \"temperature_2m,wind_speed_10m\",\n",
        "                \"hourly\": \"temperature_2m,relative_humidity_2m,wind_speed_10m\",\n",
        "            },\n",
        "        )\n",
        "    return response.json()[\"current\"][\"temperature_2m\"]\n",
        "\n",
        "\n",
        "# Define the Pydantic tool schema\n",
        "class WeatherToolSchema(BaseModel):\n",
        "    \"\"\"Get current temperature for provided coordinates in celsius.\"\"\"\n",
        "\n",
        "    latitude: float = Field(\n",
        "        ..., description=\"Latitude of the location to get weather for.\"\n",
        "    )\n",
        "    longitude: float = Field(\n",
        "        ..., description=\"Longitude of the location to get weather for.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Register the tool with OpenAI\n",
        "weather_tool_schema = pydantic_function_tool(WeatherToolSchema, name=\"get_weather\")\n",
        "\n",
        "# Step 1: Ask the model to select and call the right tool\n",
        "tool_call_response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=message_history,\n",
        "    tools=[weather_tool_schema],\n",
        ")\n",
        "\n",
        "# Step 2: Add the assistant's tool call to the conversation history\n",
        "message_history.append(\n",
        "    cast(\n",
        "        ChatCompletionAssistantMessageParam,\n",
        "        tool_call_response.choices[0].message.model_dump(),\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Step 3: Execute the tool function and add the result as a tool message\n",
        "for tool_call in tool_call_response.choices[0].message.tool_calls or []:\n",
        "    params = json.loads(tool_call.function.arguments)\n",
        "    tool_result = get_weather(params[\"latitude\"], params[\"longitude\"])\n",
        "    message_history.append(\n",
        "        ChatCompletionToolMessageParam(\n",
        "            role=\"tool\",\n",
        "            tool_call_id=tool_call.id,\n",
        "            content=str(tool_result),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Step 4: Let the model summarize and use the tool result in its final answer\n",
        "final_response = openai_client.chat.completions.create(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=message_history,\n",
        "    tools=[weather_tool_schema],\n",
        ")\n",
        "\n",
        "# Print the assistant's final answer using real API data ‚òÄÔ∏èüå°Ô∏è\n",
        "print(final_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94edea80-3ec3-472e-8c75-cd216ecc7404",
      "metadata": {},
      "source": [
        "## Structured Output\n",
        "\n",
        "Did you know you can get responses as structured Python objects, not just plain text? üòç This is extremely useful for extracting data, facts, or step-by-step answers! OpenAI uses <a href=\"https://docs.pydantic.dev/\">Pydantic</a> for easy data validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bed5072-2c2a-420b-8bb9-ce82b3a92ad2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Get step-by-step math reasoning as structured output\n",
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "from openai.types.chat import ChatCompletionSystemMessageParam\n",
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "\n",
        "# Create OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "\n",
        "# Define Pydantic classes for the expected output\n",
        "class SolutionStep(BaseModel):\n",
        "    output: str\n",
        "    explanation: str\n",
        "\n",
        "\n",
        "class MathProblemSolution(BaseModel):\n",
        "    steps: list[SolutionStep]\n",
        "    final_answer: str\n",
        "\n",
        "\n",
        "# Send a message and specify the response format\n",
        "structured_response = openai_client.chat.completions.parse(\n",
        "    model=\"openai/gpt-4.1-mini\",\n",
        "    messages=[\n",
        "        ChatCompletionSystemMessageParam(\n",
        "            role=\"system\",\n",
        "            content=\"You are a helpful math tutor. Guide the user through the solution step by step.\",\n",
        "        ),\n",
        "        ChatCompletionUserMessageParam(\n",
        "            role=\"user\", content=\"how can I solve 8x + 7 = -23\"\n",
        "        ),\n",
        "    ],\n",
        "    response_format=MathProblemSolution,\n",
        ")\n",
        "\n",
        "# Access the parsed structured response\n",
        "solution = structured_response.choices[0].message.parsed\n",
        "\n",
        "# Check if we got a valid solution and print the steps\n",
        "if solution:\n",
        "    # Print each step\n",
        "    for step_number, step in enumerate(solution.steps, 1):\n",
        "        print(f\"Step {step_number}\")\n",
        "        print(f\"Explanation: {step.explanation}\")\n",
        "        print(f\"Output: {step.output}\\n\")\n",
        "\n",
        "    # Show the final answer üßÆ\n",
        "    print(\"Final Answer:\\n\" + solution.final_answer)\n",
        "else:\n",
        "    print(\"No solution found. Please try a different problem.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff934f1",
      "metadata": {},
      "source": [
        "## Embeddings Generation\n",
        "\n",
        "Want to turn text into numerical vectors? üßÆ OpenAI's embeddings let you do just that! This is great for tasks like semantic search, clustering, and more. Embeddings are like fingerprints for your text, making it easier to find similar content or group related ideas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e89281",
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Create OpenAI client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Generate embeddings for a list of text inputs\n",
        "inputs = [\n",
        "    \"The weather is sunny and warm today.\",\n",
        "    \"Python is a popular programming language for data science.\",\n",
        "    \"How do I bake a chocolate cake from scratch?\",\n",
        "    \"Artificial intelligence will change the future of work.\",\n",
        "    \"The capital of France is Paris.\",\n",
        "    \"Can you recommend a good book to read?\",\n",
        "    \"I love hiking in the mountains during autumn.\",\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Customer support response time is critical for satisfaction.\",\n",
        "    \"She solved the math problem in just a few seconds.\",\n",
        "]\n",
        "\n",
        "# Send in inputs as batch to the embeddings API\n",
        "response = openai_client.embeddings.create(input=inputs, model=\"text-embedding-3-small\")\n",
        "\n",
        "# Print the embeddings for each input and show the first few values\n",
        "for idx, embedding in enumerate(response.data):\n",
        "    print(f\"Input {idx+1}: {inputs[idx]}\")\n",
        "    print(f\"Embedding: {embedding.embedding[:3]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acknowledgements",
      "metadata": {},
      "source": [
        "## Acknowledgements\n",
        "\n",
        "> üí° _If you found this guide helpful, consider exploring the official docs and community resources below for deeper learning and up-to-date best practices!_\n",
        "\n",
        "Content and inspiration for this guide were drawn from the following resources:\n",
        "\n",
        "- üîó [OpenAI: Quickstart](https://platform.openai.com/docs/quickstart?api-mode=chat)\n",
        "- üîó [OpenAI: Embeddings](https://platform.openai.com/docs/guides/embeddings)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "x-created-at": "2025-06-25T00:00:00Z",
    "x-tags": [
      "openai"
    ]
  },
  "nbformat": 4,
  "nbformat_minor": 5
}